#!/usr/bin/env python3
"""
ä¼šè©±GUIã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³

ã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰æ¤œçŸ¥å¾Œã«èµ·å‹•ã•ã‚Œã€OpenAI Realtime APIã‚’ä½¿ç”¨ã—ãŸ
ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°å¯¾è©±ã‚’æä¾›ã—ã¾ã™ã€‚15ç§’ã®ç„¡æ“ä½œã§è‡ªå‹•çµ‚äº†ã—ã€
ãƒ‡ãƒ¼ãƒ¢ãƒ³ãŒã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰æ¤œçŸ¥ãƒ¢ãƒ¼ãƒ‰ã«æˆ»ã‚Šã¾ã™ã€‚

ä¸»è¦æ©Ÿèƒ½:
- OpenAI Realtime APIã¨ã®WebSocketæ¥ç¶š
- ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°å…¥å‡ºåŠ›ï¼ˆ24kHz PCM16ï¼‰
- Live2Dé¢¨ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³
- ç™ºè©±ãƒ†ã‚­ã‚¹ãƒˆã®ç”»é¢è¡¨ç¤ºï¼ˆæ—¥æœ¬èªå¯¾å¿œï¼‰
- ç„¡æ“ä½œã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼ˆ15ç§’ï¼‰

å‹•ä½œãƒ•ãƒ­ãƒ¼:
1. wake_word_daemon.pyã‹ã‚‰èµ·å‹•
2. OpenAI Realtime APIã«æ¥ç¶š
3. ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®éŸ³å£°å…¥åŠ›ã‚’å—ã‘ä»˜ã‘
4. AIã®å¿œç­”ã‚’éŸ³å£°ã¨ãƒ†ã‚­ã‚¹ãƒˆã§è¡¨ç¤º
5. 15ç§’ç„¡æ“ä½œã§ã‚¢ãƒ—ãƒªçµ‚äº†
6. ãƒ‡ãƒ¼ãƒ¢ãƒ³ãŒã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰æ¤œçŸ¥ã‚’å†é–‹
"""

import asyncio
import time
from src.audio import AudioHandler
from src.realtime_client import RealtimeClient
from src.gui import GUIHandler

# ================================================================================
# çŠ¶æ…‹å®šæ•°
# ================================================================================
STATE_LISTENING = "LISTENING"    # èã„ã¦ã„ã‚‹ï¼ˆç·‘è‰²ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼ï¼‰
STATE_PROCESSING = "PROCESSING"  # è€ƒãˆä¸­ï¼ˆé»„è‰²ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼ï¼‰
STATE_SPEAKING = "SPEAKING"      # ç™ºè©±ä¸­ï¼ˆå£ãƒ‘ã‚¯ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰


class ConversationApp:
    """
    ä¼šè©±GUIã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ç®¡ç†ã‚¯ãƒ©ã‚¹

    OpenAI Realtime APIã¨ã®æ¥ç¶šã€éŸ³å£°å…¥å‡ºåŠ›ã€GUIè¡¨ç¤ºã€
    ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³åˆ¶å¾¡ã€ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆç®¡ç†ã‚’ä¸€å…ƒçš„ã«è¡Œã„ã¾ã™ã€‚

    Attributes:
        state (str): ç¾åœ¨ã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³çŠ¶æ…‹
        gui (GUIHandler): GUIè¡¨ç¤ºã¨ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ç®¡ç†
        audio (AudioHandler): éŸ³å£°å…¥å‡ºåŠ›ç®¡ç†
        client (RealtimeClient): OpenAI Realtime APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
        audio_queue (asyncio.Queue): AIå¿œç­”éŸ³å£°ã®ãƒãƒƒãƒ•ã‚¡
        is_playing_response (bool): å¿œç­”éŸ³å£°å†ç”Ÿä¸­ãƒ•ãƒ©ã‚°
        last_interaction_time (float): æœ€å¾Œã®æ“ä½œæ™‚åˆ»ï¼ˆUnixæ™‚é–“ï¼‰
        response_in_progress (bool): AIå¿œç­”å‡¦ç†ä¸­ãƒ•ãƒ©ã‚°
        interrupt_active (bool): å‰²ã‚Šè¾¼ã¿ä¸­ãƒ•ãƒ©ã‚°ï¼ˆTrueæ™‚ã¯éŸ³å£°å—ä¿¡ã‚’ç ´æ£„ï¼‰
        inactivity_timeout (float): ç„¡æ“ä½œã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆæ™‚é–“ï¼ˆç§’ï¼‰
        connection_time (float): APIæ¥ç¶šæ™‚åˆ»ï¼ˆãƒã‚¤ã‚ºé™¤å¤–ç”¨ï¼‰
    """
    def __init__(self):
        """
        ConversationAppã‚’åˆæœŸåŒ–

        GUIã€ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã€Realtime APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’åˆæœŸåŒ–ã—ã€
        å„ç¨®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’è¨­å®šã—ã¾ã™ã€‚
        """
        self.state = STATE_LISTENING
        self.gui = GUIHandler()
        self.audio = AudioHandler()

        # OpenAI Realtime APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–ï¼ˆã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯è¨­å®šï¼‰
        self.client = RealtimeClient(
            on_audio_delta=self.handle_audio_delta,          # AIå¿œç­”éŸ³å£°å—ä¿¡æ™‚
            on_user_transcript=self.handle_user_transcript,  # ãƒ¦ãƒ¼ã‚¶ãƒ¼ç™ºè©±ãƒ†ã‚­ã‚¹ãƒˆå—ä¿¡æ™‚
            on_agent_transcript=self.handle_agent_transcript,  # AIå¿œç­”ãƒ†ã‚­ã‚¹ãƒˆå—ä¿¡æ™‚
            on_speech_started=self.on_user_speech_start,    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ç™ºè©±é–‹å§‹æ¤œçŸ¥æ™‚
            on_response_done=self.on_response_done,         # AIå¿œç­”å®Œäº†æ™‚
            on_response_created=self.on_response_created    # AIå¿œç­”ç”Ÿæˆé–‹å§‹æ™‚ï¼ˆå‰²ã‚Šè¾¼ã¿åˆ¤å®šç”¨ï¼‰
        )

        # éŸ³å£°å†ç”Ÿãƒãƒƒãƒ•ã‚¡ã¨ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆç®¡ç†
        self.audio_queue = asyncio.Queue()      # AIå¿œç­”éŸ³å£°ã®ãƒãƒƒãƒ•ã‚¡ãƒªãƒ³ã‚°ç”¨ã‚­ãƒ¥ãƒ¼
        self.is_playing_response = False        # éŸ³å£°å†ç”Ÿä¸­ãƒ•ãƒ©ã‚°
        self.last_interaction_time = time.time()  # æœ€å¾Œã®æ“ä½œæ™‚åˆ»ï¼ˆã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆåˆ¤å®šç”¨ï¼‰
        self.response_in_progress = False       # AIå¿œç­”å‡¦ç†ä¸­ãƒ•ãƒ©ã‚°
        self.interrupt_active = False           # å‰²ã‚Šè¾¼ã¿ä¸­ãƒ•ãƒ©ã‚°ï¼ˆéŸ³å£°å—ä¿¡ã‚’ç„¡è¦–ï¼‰
        self.inactivity_timeout = 60.0          # ç„¡æ“ä½œã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼ˆ60ç§’ï¼‰
        self.connection_time = 0                # APIæ¥ç¶šæ™‚åˆ»ï¼ˆãƒã‚¤ã‚ºé™¤å¤–ç”¨ï¼‰

    async def run(self):
        """
        ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—

        OpenAI Realtime APIã«æ¥ç¶šã—ã€éŸ³å£°å…¥å‡ºåŠ›ã¨GUIæ›´æ–°ã‚’ä¸¦è¡Œå‡¦ç†ã—ã¾ã™ã€‚
        ç„¡æ“ä½œã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼ˆ15ç§’ï¼‰ã§ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’çµ‚äº†ã—ã¾ã™ã€‚

        å‡¦ç†ãƒ•ãƒ­ãƒ¼:
        1. éŸ³å£°ã‚¹ãƒˆãƒªãƒ¼ãƒ é–‹å§‹
        2. OpenAI APIã«æ¥ç¶š
        3. ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—ï¼ˆGUIæ›´æ–°ã€éŸ³å£°å†ç”Ÿã€ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆç›£è¦–ï¼‰
        4. ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        """
        print("Conversation App Started")

        # ================================================================================
        # éŸ³å£°ã‚¹ãƒˆãƒªãƒ¼ãƒ ã®é–‹å§‹
        # ================================================================================
        self.audio.start_stream(input_callback=self.audio_input_callback)
        asyncio.create_task(self.audio.record_loop())

        # ================================================================================
        # OpenAI Realtime APIã«æ¥ç¶š
        # ================================================================================
        try:
            await self.client.connect()
            self.connection_time = time.time()  # æ¥ç¶šæ™‚åˆ»ã‚’è¨˜éŒ²
            self.last_interaction_time = time.time()
            self.gui.set_state(1)  # LISTENINGï¼ˆç·‘è‰²ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼ï¼‰
            print("Connected to OpenAI Realtime API")
        except Exception as e:
            print(f"Failed to connect: {e}")
            self.gui.running = False
            return

        # ================================================================================
        # ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—
        # ================================================================================
        while self.gui.running:
            # GUIæ›´æ–°ï¼ˆã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ã€ãƒ†ã‚­ã‚¹ãƒˆè¡¨ç¤ºã€ã‚¤ãƒ™ãƒ³ãƒˆå‡¦ç†ï¼‰
            self.gui.update()

            # ç„¡æ“ä½œã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆãƒã‚§ãƒƒã‚¯ï¼ˆ15ç§’ï¼‰
            elapsed = time.time() - self.last_interaction_time
            if elapsed > self.inactivity_timeout:
                print(f"[TIMEOUT] Inactivity timeout ({self.inactivity_timeout}s elapsed: {elapsed:.1f}s). Exiting conversation.")
                self.gui.running = False
                break

            # AIå¿œç­”éŸ³å£°ã®å†ç”Ÿï¼ˆã‚­ãƒ¥ãƒ¼ã‹ã‚‰å–ã‚Šå‡ºã—ã¦å†ç”Ÿï¼‰
            if not self.audio_queue.empty():
                if not self.is_playing_response:
                    self.is_playing_response = True
                    self.gui.set_state(3)  # SPEAKINGï¼ˆå£ãƒ‘ã‚¯ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰
                self.last_interaction_time = time.time()  # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆãƒªã‚»ãƒƒãƒˆ

                chunk = await self.audio_queue.get()
                # ãƒãƒ£ãƒ³ã‚¯å–å¾—ç›´å¾Œã«å‰²ã‚Šè¾¼ã¿ãŒç™ºç”Ÿã—ã¦ã„ãªã„ã‹å†ç¢ºèª
                if not self.interrupt_active:
                    # play_audioã‚’ã‚¹ãƒ¬ãƒƒãƒ‰ã§å®Ÿè¡Œã—ã¦ãƒ–ãƒ­ãƒƒã‚­ãƒ³ã‚°ã‚’å›é¿
                    await asyncio.get_event_loop().run_in_executor(None, self.audio.play_audio, chunk)
            else:
                # éŸ³å£°å†ç”Ÿå®Œäº†æ™‚ã€LISTENINGãƒ¢ãƒ¼ãƒ‰ã«æˆ»ã‚‹
                if self.is_playing_response:
                    self.is_playing_response = False
                    self.gui.set_state(1)  # Back to LISTENING
                    print("[PLAYBACK] All audio chunks played, back to LISTENING")

            await asyncio.sleep(0.001)  # ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—ã«åˆ¶å¾¡ã‚’è¿”ã™

        # ================================================================================
        # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        # ================================================================================
        await self.cleanup()

    def audio_input_callback(self, in_data):
        """
        ãƒã‚¤ã‚¯å…¥åŠ›ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯

        AudioHandlerã‹ã‚‰å‘¼ã°ã‚Œã€éŒ²éŸ³ã•ã‚ŒãŸéŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’
        OpenAI Realtime APIã«é€ä¿¡ã—ã¾ã™ã€‚

        Args:
            in_data (bytes): éŒ²éŸ³ã•ã‚ŒãŸéŸ³å£°ãƒ‡ãƒ¼ã‚¿ï¼ˆPCM16, 24kHz, ãƒ¢ãƒãƒ©ãƒ«ï¼‰
        """
        try:
            loop = asyncio.get_running_loop()
            loop.create_task(self.client.send_audio(in_data))

            # ãƒ‡ãƒãƒƒã‚°: ãƒã‚¤ã‚¯å…¥åŠ›é€ä¿¡ã‚’å®šæœŸçš„ã«ãƒ­ã‚°å‡ºåŠ›
            if not hasattr(self, '_input_counter'):
                self._input_counter = 0
            self._input_counter += 1
            if self._input_counter % 100 == 0:  # 100ãƒãƒ£ãƒ³ã‚¯ã”ã¨ã«å‡ºåŠ›
                print(f"[MIC] Sending audio to API (chunk #{self._input_counter}, {len(in_data)} bytes)")
        except RuntimeError:
            pass  # ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—æœªèµ·å‹•æ™‚ã¯ç„¡è¦–

    def on_user_speech_start(self):
        """
        ãƒ¦ãƒ¼ã‚¶ãƒ¼ç™ºè©±é–‹å§‹ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆå‰²ã‚Šè¾¼ã¿å‡¦ç†ï¼‰

        OpenAI Realtime APIãŒãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç™ºè©±é–‹å§‹ã‚’æ¤œçŸ¥ã—ãŸéš›ã«å‘¼ã°ã‚Œã¾ã™ã€‚
        AIå¿œç­”ä¸­ã®å ´åˆã¯å‰²ã‚Šè¾¼ã¿å‡¦ç†ã‚’å®Ÿè¡Œã—ã€å³åº§ã«éŸ³å£°ã‚’åœæ­¢ã—ã¾ã™ã€‚

        å‰²ã‚Šè¾¼ã¿å‡¦ç†ãƒ•ãƒ­ãƒ¼:
        1. ãƒ­ãƒ¼ã‚«ãƒ«éŸ³å£°ã‚­ãƒ¥ãƒ¼ã‚’ã‚¯ãƒªã‚¢ï¼ˆæœªå†ç”Ÿã®AIéŸ³å£°ã‚’ç ´æ£„ï¼‰
        2. éŸ³å£°å†ç”Ÿã‚’åœæ­¢ï¼ˆç¾åœ¨å†ç”Ÿä¸­ã®éŸ³å£°ã‚’ä¸­æ–­ï¼‰
        3. Realtime APIã«å¿œç­”ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã‚’é€ä¿¡
        4. GUIã‚’PROCESSINGçŠ¶æ…‹ã«æ›´æ–°
        """
        # æ¥ç¶šç›´å¾Œ2ç§’é–“ã¯ãƒã‚¤ã‚ºã¨ã—ã¦ç„¡è¦–
        if time.time() - self.connection_time < 2.0:
            print("[BARGE-IN] Ignoring noise during connection startup")
            return

        print("[BARGE-IN] User speech started - initiating interrupt")
        self.last_interaction_time = time.time()  # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆãƒªã‚»ãƒƒãƒˆ

        # ğŸ†• å‰²ã‚Šè¾¼ã¿ãƒ•ãƒ©ã‚°ã‚’ç«‹ã¦ã‚‹ï¼ˆæ–°ã—ã„éŸ³å£°ãƒãƒ£ãƒ³ã‚¯ã‚’æ‹’å¦ï¼‰
        self.interrupt_active = True
        print("[BARGE-IN] Interrupt flag set - will ignore incoming audio")

        # ğŸ†• å‰²ã‚Šè¾¼ã¿å‡¦ç†ï¼šéŸ³å£°ã‚­ãƒ¥ãƒ¼ã‚’ã‚¯ãƒªã‚¢ï¼ˆå¸¸ã«å®Ÿè¡Œï¼‰
        queue_size = self.audio_queue.qsize()
        if queue_size > 0:
            print(f"[BARGE-IN] Clearing audio queue ({queue_size} chunks)")
            while not self.audio_queue.empty():
                try:
                    self.audio_queue.get_nowait()
                except asyncio.QueueEmpty:
                    break
        else:
            print("[BARGE-IN] Audio queue already empty")

        # ğŸ†• å‰²ã‚Šè¾¼ã¿å‡¦ç†ï¼šéŸ³å£°å†ç”Ÿã‚’åœæ­¢ï¼ˆãƒ•ãƒ©ã‚°ã«é–¢ä¿‚ãªãå¸¸ã«å®Ÿè¡Œï¼‰
        # ç†ç”±: play_audio()ã¯ãƒãƒƒãƒ•ã‚¡ã«æ›¸ãè¾¼ã‚€ã ã‘ã§ã€å®Ÿéš›ã®å†ç”Ÿã¯é…å»¶ã™ã‚‹
        # ã‚­ãƒ¥ãƒ¼ãŒç©ºã§ã‚‚ã€ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼ãƒãƒƒãƒ•ã‚¡ã«ã¯ã¾ã éŸ³å£°ãŒæ®‹ã£ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹
        print("[BARGE-IN] Forcing audio playback stop")
        self.audio.stop_playback()

        # ğŸ†• å‰²ã‚Šè¾¼ã¿å‡¦ç†ï¼šRealtime APIã«ä¸­æ–­ã‚’é€šçŸ¥
        # å¿œç­”ç”Ÿæˆä¸­ã®å ´åˆã®ã¿ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã‚’é€ä¿¡ï¼ˆã‚µãƒ¼ãƒãƒ¼å´ã‚¨ãƒ©ãƒ¼å›é¿ï¼‰
        if self.response_in_progress:
            print(f"[BARGE-IN] Sending cancel (in_progress={self.response_in_progress}, is_playing={self.is_playing_response})")
            asyncio.create_task(self.client.cancel_response())
        else:
            print("[BARGE-IN] No active response to cancel on server")

        self.response_in_progress = False
        self.is_playing_response = False
        self.gui.reset_texts()  # ğŸ†• GUIå´ã®ãƒ†ã‚­ã‚¹ãƒˆè¡¨ç¤ºã‚’å³åº§ã«ãƒªã‚»ãƒƒãƒˆ
        self.gui.set_state(2)  # PROCESSINGï¼ˆè€ƒãˆä¸­ï¼‰
        print("[BARGE-IN] Interrupt complete")

    def on_response_created(self):
        """
        AIå¿œç­”ç”Ÿæˆé–‹å§‹ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯

        OpenAI Realtime APIãŒAIå¿œç­”ã®ç”Ÿæˆã‚’é–‹å§‹ã—ãŸéš›ã«å‘¼ã°ã‚Œã¾ã™ã€‚
        å‰²ã‚Šè¾¼ã¿åˆ¤å®šã®ãŸã‚ã«ã€å¿œç­”ç”Ÿæˆä¸­ãƒ•ãƒ©ã‚°ã‚’ç«‹ã¦ã¾ã™ã€‚
        æ–°ã—ã„å¿œç­”ãŒé–‹å§‹ã•ã‚ŒãŸãŸã‚ã€å‰²ã‚Šè¾¼ã¿ãƒ•ãƒ©ã‚°ã‚’ãƒªã‚»ãƒƒãƒˆã—ã¾ã™ã€‚
        """
        print("Response created (generation started)")
        self.response_in_progress = True
        self.interrupt_active = False  # æ–°ã—ã„å¿œç­”é–‹å§‹ã€å‰²ã‚Šè¾¼ã¿ãƒ•ãƒ©ã‚°ã‚’ãƒªã‚»ãƒƒãƒˆ
        print("[RESPONSE] Interrupt flag cleared - accepting new audio")
        self.last_interaction_time = time.time()  # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆãƒªã‚»ãƒƒãƒˆ

    def on_response_done(self):
        """
        AIå¿œç­”å®Œäº†ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯

        OpenAI Realtime APIãŒAIå¿œç­”ã®ç”Ÿæˆã‚’å®Œäº†ã—ãŸéš›ã«å‘¼ã°ã‚Œã¾ã™ã€‚
        å¿œç­”ç”Ÿæˆä¸­ãƒ•ãƒ©ã‚°ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã™ã€‚
        """
        print("Response done")
        self.response_in_progress = False
        self.last_interaction_time = time.time()  # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆãƒªã‚»ãƒƒãƒˆ

    def handle_audio_delta(self, audio_bytes):
        """
        AIå¿œç­”éŸ³å£°å—ä¿¡ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯

        OpenAI Realtime APIã‹ã‚‰å—ä¿¡ã—ãŸéŸ³å£°ãƒ‡ãƒ«ã‚¿ã‚’ã‚­ãƒ¥ãƒ¼ã«è¿½åŠ ã—ã¾ã™ã€‚
        ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—ã§é †æ¬¡å†ç”Ÿã•ã‚Œã¾ã™ã€‚

        å‰²ã‚Šè¾¼ã¿ä¸­ï¼ˆinterrupt_active=Trueï¼‰ã®å ´åˆã¯ã€å—ä¿¡ã—ãŸéŸ³å£°ã‚’ç ´æ£„ã—ã¾ã™ã€‚
        ã“ã‚Œã«ã‚ˆã‚Šã€APIãŒã‚­ãƒ£ãƒ³ã‚»ãƒ«å¾Œã‚‚é€ä¿¡ã—ã¦ãã‚‹éŸ³å£°ãƒãƒ£ãƒ³ã‚¯ã‚’ç„¡è¦–ã§ãã¾ã™ã€‚

        Args:
            audio_bytes (bytes): AIå¿œç­”éŸ³å£°ãƒ‡ãƒ¼ã‚¿ï¼ˆPCM16, 24kHz, ãƒ¢ãƒãƒ©ãƒ«ï¼‰
        """
        self.last_interaction_time = time.time()  # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆãƒªã‚»ãƒƒãƒˆ

        # å‰²ã‚Šè¾¼ã¿ä¸­ã¯éŸ³å£°ãƒãƒ£ãƒ³ã‚¯ã‚’ç ´æ£„
        if self.interrupt_active:
            print(f"[AUDIO] Ignoring audio chunk during interrupt ({len(audio_bytes)} bytes)")
            return

        # Note: response_in_progress ã¯ on_response_created ã§ç®¡ç†ã•ã‚Œã‚‹
        self.audio_queue.put_nowait(audio_bytes)

    def handle_user_transcript(self, text):
        """
        ãƒ¦ãƒ¼ã‚¶ãƒ¼ç™ºè©±ãƒ†ã‚­ã‚¹ãƒˆå—ä¿¡ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯
        """
        print(f"User: {text}")
        self.gui.set_user_text(text)

        # ğŸ†• çµ‚äº†ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®ãƒã‚§ãƒƒã‚¯
        exit_keywords = ["ã‚¹ãƒˆãƒƒãƒ—", "ãŠã‚ã‚Š", "çµ‚ã‚ã‚Š", "çµ‚äº†", "ãƒã‚¤ãƒã‚¤", "ã•ã‚ˆã†ãªã‚‰", "ã¾ãŸã­"]
        if any(kw in text for kw in exit_keywords):
            print(f"[EXIT] Exit keyword detected in user speech: {text}")
            # AIãŒæœ€å¾Œã«å¿œç­”ã™ã‚‹æ™‚é–“ã‚’å°‘ã—ã ã‘ç¢ºä¿ã—ã¦ã‹ã‚‰çµ‚äº†ã™ã‚‹ã‚ˆã†ã«ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«
            asyncio.create_task(self.delayed_exit(2.0))

    async def delayed_exit(self, delay):
        """
        æŒ‡å®šç§’æ•°å¾Œã«ã‚¢ãƒ—ãƒªã‚’çµ‚äº†ã™ã‚‹
        """
        await asyncio.sleep(delay)
        print("[EXIT] Exiting application by voice command.")
        self.gui.running = False

    def handle_agent_transcript(self, text):
        """
        AIå¿œç­”ãƒ†ã‚­ã‚¹ãƒˆå—ä¿¡ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯

        OpenAI Realtime APIã‹ã‚‰å—ä¿¡ã—ãŸAIå¿œç­”ã®ãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’
        GUIã«è¡¨ç¤ºã—ã¾ã™ã€‚

        Args:
            text (str): AIå¿œç­”ã®ãƒ†ã‚­ã‚¹ãƒˆ
        """
        print(f"Agent: {text}")
        self.gui.set_agent_text(text)

    async def cleanup(self):
        """
        ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—

        WebSocketæ¥ç¶šã‚’åˆ‡æ–­ã—ã€éŸ³å£°ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’åœæ­¢ã—ã€
        GUIã‚’çµ‚äº†ã—ã¾ã™ã€‚
        """
        print("Cleaning up conversation app...")
        await self.client.close()
        self.audio.terminate()
        self.gui.quit()
        print("Conversation app exited")

if __name__ == "__main__":
    app = ConversationApp()
    try:
        asyncio.run(app.run())
    except KeyboardInterrupt:
        print("\nInterrupted")
    except Exception as e:
        print(f"Error: {e}")
        import traceback
        traceback.print_exc()
